
# coding: utf-8

# # èƒ¶å›Šç½‘ç»œ(CapsNets) 

# åŸºäºè®ºæ–‡ï¼š[Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829)ï¼Œä½œè€…ï¼šSara Sabour, Nicholas Frosst and Geoffrey E. Hinton (NIPS 2017)ã€‚

# éƒ¨åˆ†å¯å‘æ¥è‡ªäºHuadong Liaoçš„å®ç°[CapsNet-TensorFlow](https://github.com/naturomics/CapsNet-Tensorflow)

# # ç®€ä»‹

# è§‚çœ‹ [è§†é¢‘](https://youtu.be/pPN8d0E3900)æ¥ç†è§£èƒ¶å›Šç½‘ç»œèƒŒåçš„å…³é”®æƒ³æ³•ï¼ˆå¤§å®¶å¯èƒ½çœ‹ä¸åˆ°ï¼Œå› ä¸ºyoutubeè¢«å¢™äº†ï¼‰ï¼š

# In[157]:


from IPython.display import HTML
HTML("""<iframe width="560" height="315" src="https://www.youtube.com/embed/pPN8d0E3900" frameborder="0" allowfullscreen></iframe>""")


# ä½ æˆ–è®¸ä¹Ÿéœ€è¦è§‚çœ‹[è§†é¢‘](https://youtu.be/2Kawrd5szHE)ï¼Œå…¶å±•ç¤ºäº†è¿™ä¸ªnotebookçš„éš¾ç‚¹ï¼ˆå¤§å®¶å¯èƒ½çœ‹ä¸åˆ°ï¼Œå› ä¸ºyoutubeè¢«å¢™äº†ï¼‰ï¼š

# In[158]:


HTML("""<iframe width="560" height="315" src="https://www.youtube.com/embed/2Kawrd5szHE" frameborder="0" allowfullscreen></iframe>""")


# # Imports

# åŒæ—¶æ”¯æŒ Python 2 å’Œ Python 3ï¼š

# In[78]:


from __future__ import division, print_function, unicode_literals


# ä¸ºäº†ç»˜åˆ¶å¥½çœ‹çš„å›¾ï¼š

# In[79]:


get_ipython().run_line_magic('matplotlib', 'inline')
import matplotlib
import matplotlib.pyplot as plt


# æˆ‘ä»¬ä¼šç”¨åˆ° NumPy å’Œ TensorFlowï¼š

# In[80]:


import numpy as np
import tensorflow as tf


# # å¯é‡å¤æ€§

# ä¸ºäº†èƒ½å¤Ÿåœ¨ä¸é‡æ–°å¯åŠ¨Jupyter Notebook Kernelçš„æƒ…å†µä¸‹é‡æ–°è¿è¡Œæœ¬notebookï¼Œæˆ‘ä»¬éœ€è¦é‡ç½®é»˜è®¤çš„è®¡ç®—å›¾ã€‚

# In[81]:


tf.reset_default_graph()


# è®¾ç½®éšæœºç§å­ï¼Œä»¥ä¾¿äºæœ¬notebookæ€»æ˜¯å¯ä»¥è¾“å‡ºç›¸åŒçš„è¾“å‡ºï¼š

# In[82]:


np.random.seed(42)
tf.set_random_seed(42)


# # è£…è½½MNIST

# æ˜¯çš„ï¼Œæˆ‘çŸ¥é“ï¼Œåˆæ˜¯MNISTã€‚ä½†æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªæå…·å¨åŠ›çš„æƒ³æ³•å¯ä»¥å·¥ä½œåœ¨æ›´å¤§çš„æ•°æ®é›†ä¸Šï¼Œæ—¶é—´ä¼šè¯´æ˜ä¸€åˆ‡ã€‚ï¼ˆè¯‘æ³¨ï¼šå› ä¸ºæ˜¯Hintonå—ï¼Œå› ä¸ºä»–è€æ˜¯å¯¹;-)ï¼Ÿï¼‰

# In[83]:


from tensorflow.examples.tutorials.mnist import input_data

mnist = input_data.read_data_sets("/tmp/data/")


# è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹è¿™äº›æ‰‹å†™æ•°å­—å›¾åƒæ˜¯ä»€ä¹ˆæ ·çš„ï¼š

# In[84]:


n_samples = 5

plt.figure(figsize=(n_samples * 2, 3))
for index in range(n_samples):
    plt.subplot(1, n_samples, index + 1)
    sample_image = mnist.train.images[index].reshape(28, 28)
    plt.imshow(sample_image, cmap="binary")
    plt.axis("off")

plt.show()


# ä»¥åŠç›¸åº”çš„æ ‡ç­¾ï¼š

# In[85]:


mnist.train.labels[:n_samples]


# ç°åœ¨è®©æˆ‘ä»¬å»ºç«‹ä¸€ä¸ªèƒ¶å›Šç½‘ç»œæ¥åŒºåˆ†è¿™äº›å›¾åƒã€‚è¿™é‡Œæœ‰ä¸€ä¸ªå…¶æ€»ä½“çš„æ¶æ„ï¼Œäº«å—ä¸€ä¸‹ASCIIå­—ç¬¦çš„è‰ºæœ¯å§! ;-)
# æ³¨æ„ï¼šä¸ºäº†å¯è¯»æ€§ï¼Œæˆ‘æ‘’å¼ƒäº†ä¸¤ç§ç®­å¤´ï¼šæ ‡ç­¾ â†’ æ©ç›–ï¼Œä»¥åŠ è¾“å…¥çš„å›¾åƒ â†’ é‡æ–°æ„é€ æŸå¤±ã€‚

# ```
#                             æŸ å¤±
#                               â†‘
#                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#           æ ‡ ç­¾ â†’ è¾¹ é™… æŸ å¤±     é‡ æ–° æ„ é€  æŸ å¤±
#                     â†‘                   â†‘
#                   æ¨¡ é•¿               è§£ ç  å™¨
#                     â†‘                   â†‘ 
#              æ•° å­— èƒ¶ å›Š ä»¬  â”€â”€â”€â”€é® ç›–â”€â”€â”€â”€â”€â”˜
#                â†–â†‘â†— â†–â†‘â†— â†–â†‘â†—
#                  ä¸» èƒ¶ å›Š ä»¬
#                     â†‘      
#                è¾“ å…¥ çš„ å›¾ åƒ
# ```

# æˆ‘ä»¬æ‰“ç®—ä»åº•å±‚å¼€å§‹æ„å»ºè¯¥è®¡ç®—å›¾ï¼Œç„¶åé€æ­¥ä¸Šç§»ï¼Œå·¦ä¾§ä¼˜å…ˆã€‚è®©æˆ‘ä»¬å¼€å§‹ï¼

# # è¾“å…¥å›¾åƒ

# è®©æˆ‘ä»¬é€šè¿‡ä¸ºè¾“å…¥å›¾åƒåˆ›å»ºä¸€ä¸ªå ä½ç¬¦ä½œä¸ºèµ·æ­¥ï¼Œè¯¥è¾“å…¥å›¾åƒå…·æœ‰28Ã—28ä¸ªåƒç´ ï¼Œ1ä¸ªé¢œè‰²é€šé“=ç°åº¦ã€‚

# In[86]:


X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name="X")


# # ä¸»èƒ¶å›Š

# ç¬¬ä¸€å±‚ç”±32ä¸ªç‰¹å¾æ˜ å°„ç»„æˆï¼Œæ¯ä¸ªç‰¹å¾æ˜ å°„ä¸º6$\times$6ä¸ªèƒ¶å›Šï¼Œå…¶ä¸­æ¯ä¸ªèƒ¶å›Šè¾“å‡º8ç»´çš„æ¿€æ´»å‘é‡ï¼š

# In[87]:


caps1_n_maps = 32
caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 ä¸»èƒ¶å›Šä»¬
caps1_n_dims = 8


# ä¸ºäº†è®¡ç®—å®ƒä»¬çš„è¾“å‡ºï¼Œæˆ‘ä»¬é¦–å…ˆåº”ç”¨ä¸¤ä¸ªå¸¸è§„çš„å·ç§¯å±‚ï¼š

# In[88]:


conv1_params = {
    "filters": 256,
    "kernel_size": 9,
    "strides": 1,
    "padding": "valid",
    "activation": tf.nn.relu,
}

conv2_params = {
    "filters": caps1_n_maps * caps1_n_dims, # 256 ä¸ªå·ç§¯æ»¤æ³¢å™¨
    "kernel_size": 9,
    "strides": 2,
    "padding": "valid",
    "activation": tf.nn.relu
}


# In[89]:


conv1 = tf.layers.conv2d(X, name="conv1", **conv1_params)
conv2 = tf.layers.conv2d(conv1, name="conv2", **conv2_params)


# æ³¨æ„ï¼šç”±äºæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå°ºå¯¸ä¸º9çš„æ ¸ï¼Œå¹¶ä¸”æ²¡æœ‰ä½¿ç”¨å¡«å……ï¼ˆå‡ºäºæŸç§åŸå› ï¼Œè¿™å°±æ˜¯`"valid"`çš„å«ä¹‰ï¼‰ï¼Œè¯¥å›¾åƒæ¯ç»å†ä¸€ä¸ªå·ç§¯å±‚å°±ä¼šç¼©å‡ $9-1=8$ ä¸ªåƒç´ ï¼ˆä» $28\times 28$ åˆ° $20 \times 20$ï¼Œå†ä» $20\times 20$ åˆ° $12\times 12$ï¼‰ï¼Œå¹¶ä¸”ç”±äºåœ¨ç¬¬äºŒä¸ªå·ç§¯å±‚ä¸­ä½¿ç”¨äº†å¤§å°ä¸º2çš„æ­¥å¹…ï¼Œé‚£ä¹ˆè¯¥å›¾åƒçš„å¤§å°å°±è¢«é™¤ä»¥2ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬æœ€åä¼šå¾—åˆ° $6\times 6$ çš„ç‰¹å¾æ˜ å°„ï¼ˆfeature mapï¼‰ã€‚

# æ¥ç€ï¼Œæˆ‘ä»¬é‡å¡‘è¯¥è¾“å‡ºä»¥è·å¾—ä¸€ç»„8Då‘é‡ï¼Œç”¨æ¥è¡¨ç¤ºä¸»èƒ¶å›Šçš„è¾“å‡ºã€‚`conv2`çš„è¾“å‡ºæ˜¯ä¸€ä¸ªæ•°ç»„ï¼ŒåŒ…å«å¯¹äºæ¯ä¸ªå®ä¾‹éƒ½æœ‰32Ã—8=256ä¸ªç‰¹å¾æ˜ å°„ï¼ˆfeature mapï¼‰ï¼Œå…¶ä¸­æ¯ä¸ªç‰¹å¾æ˜ å°„ä¸º6Ã—6ã€‚æ‰€ä»¥è¯¥è¾“å‡ºçš„å½¢çŠ¶ä¸º (_batch size_, 6, 6, 256)ã€‚æˆ‘ä»¬æƒ³è¦æŠŠ256åˆ†åˆ°32ä¸ª8ç»´å‘é‡ä¸­ï¼Œå¯ä»¥é€šè¿‡ä½¿ç”¨é‡å¡‘ (_batch size_, 6, 6, 32, 8)æ¥è¾¾åˆ°ç›®çš„ã€‚ç„¶è€Œï¼Œç”±äºé¦–ä¸ªèƒ¶å›Šå±‚ä¼šè¢«å®Œå…¨è¿æ¥åˆ°ä¸‹ä¸€ä¸ªèƒ¶å›Šå±‚ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥ç®€å•åœ°æŠŠå®ƒæ‰å¹³æˆ6Ã—6çš„ç½‘æ ¼ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬åªéœ€è¦æŠŠå®ƒé‡å¡‘æˆ (_batch size_, 6Ã—6Ã—32, 8) å³å¯ã€‚

# In[90]:


caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],
                       name="caps1_raw")


# ç°åœ¨æˆ‘ä»¬éœ€è¦å‹ç¼©è¿™äº›å‘é‡ã€‚è®©æˆ‘ä»¬æ¥å®šä¹‰`squash()`å‡½æ•°ï¼ŒåŸºäºè®ºæ–‡ä¸­çš„å…¬å¼ï¼ˆ1ï¼‰ï¼š
# 
# $\operatorname{squash}(\mathbf{s}) = \dfrac{\|\mathbf{s}\|^2}{1 + \|\mathbf{s}\|^2} \dfrac{\mathbf{s}}{\|\mathbf{s}\|}$
# 
# è¯¥`squash()`å‡½æ•°å°†ä¼šå‹ç¼©æ‰€æœ‰çš„å‘é‡åˆ°ç»™å®šçš„æ•°ç»„ä¸­ï¼Œæ²¿ç»™å®šè½´ï¼ˆé»˜è®¤æƒ…å†µä¸ºæœ€åä¸€ä¸ªè½´ï¼‰ã€‚
# 
# **å½“å¿ƒ**ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªå¾ˆè®¨åŒçš„bugåœ¨ç­‰ç€ä½ ï¼šå½“ $\|\mathbf{s}\|=0$æ—¶ï¼Œ$\|\mathbf{s}\|$ ä¸º undefinedï¼Œè¿™è®©æˆ‘ä»¬ä¸èƒ½ç›´æ¥ä½¿ç”¨ `tf.norm()`ï¼Œå¦åˆ™ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¤±è´¥ï¼šå¦‚æœä¸€ä¸ªå‘é‡ä¸º0ï¼Œé‚£ä¹ˆæ¢¯åº¦å°±ä¼šæ˜¯ `nan`ï¼Œæ‰€ä»¥å½“ä¼˜åŒ–å™¨æ›´æ–°å˜é‡æ—¶ï¼Œè¿™äº›å˜é‡ä¹Ÿä¼šå˜ä¸º `nan`ï¼Œä»é‚£ä¸ªæ—¶åˆ»èµ·ï¼Œä½ å°±æ­¢æ­¥åœ¨ `nan` é‚£é‡Œäº†ã€‚è§£å†³çš„æ–¹æ³•æ˜¯æ‰‹å·¥å®ç°normï¼Œåœ¨è®¡ç®—çš„æ—¶å€™åŠ ä¸Šä¸€ä¸ªå¾ˆå°çš„å€¼ epsilonï¼š$\|\mathbf{s}\| \approx \sqrt{\sum\limits_i{{s_i}^2}\,\,+ \epsilon}$

# In[91]:


def squash(s, axis=-1, epsilon=1e-7, name=None):
    with tf.name_scope(name, default_name="squash"):
        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,
                                     keep_dims=True)
        safe_norm = tf.sqrt(squared_norm + epsilon)
        squash_factor = squared_norm / (1. + squared_norm)
        unit_vector = s / safe_norm
        return squash_factor * unit_vector


# ç°åœ¨è®©æˆ‘ä»¬åº”ç”¨è¿™ä¸ªå‡½æ•°ä»¥è·å¾—æ¯ä¸ªä¸»èƒ¶å›Š$\mathbf{u}_i$çš„è¾“å‡ºï¼š

# In[92]:


caps1_output = squash(caps1_raw, name="caps1_output")


# å¤ªæ£’äº†ï¼æˆ‘ä»¬æœ‰äº†é¦–ä¸ªèƒ¶å›Šå±‚çš„è¾“å‡ºäº†ã€‚ä¸æ˜¯å¾ˆéš¾ï¼Œå¯¹å—ï¼Ÿç„¶åï¼Œè®¡ç®—ä¸‹ä¸€å±‚æ‰æ˜¯çœŸæ­£ä¹è¶£çš„å¼€å§‹ï¼ˆè¯‘æ³¨ï¼šå¥½æˆåˆšåˆšå¼€å§‹ï¼‰ã€‚

# # æ•°å­—èƒ¶å›Šä»¬

# è¦è®¡ç®—æ•°å­—èƒ¶å›Šä»¬çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆè®¡ç®—é¢„æµ‹çš„è¾“å‡ºå‘é‡ï¼ˆæ¯ä¸ªå¯¹åº”ä¸€ä¸ªä¸»èƒ¶å›Š/æ•°å­—èƒ¶å›Šçš„å¯¹ï¼‰ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°±å¯ä»¥é€šè¿‡åè®®ç®—æ³•æ¥è¿è¡Œè·¯ç”±ã€‚

# ## è®¡ç®—é¢„æµ‹è¾“å‡ºå‘é‡

# è¯¥æ•°å­—èƒ¶å›Šå±‚åŒ…å«10ä¸ªèƒ¶å›Šï¼ˆæ¯ä¸ªä»£è¡¨ä¸€ä¸ªæ•°å­—ï¼‰ï¼Œæ¯ä¸ªèƒ¶å›Š16ç»´ï¼š

# In[93]:


caps2_n_caps = 10
caps2_n_dims = 16


# å¯¹äºåœ¨ç¬¬ä¸€å±‚é‡Œçš„æ¯ä¸ªèƒ¶å›Š $i$ï¼Œæˆ‘ä»¬ä¼šåœ¨ç¬¬äºŒå±‚ä¸­é¢„æµ‹å‡ºæ¯ä¸ªèƒ¶å›Š $j$ çš„è¾“å‡ºã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå˜æ¢çŸ©é˜µ $\mathbf{W}_{i,j}$ï¼ˆæ¯ä¸€å¯¹å°±æ˜¯èƒ¶å›Š($i$, $j$) ä¸­çš„ä¸€ä¸ªï¼‰ï¼Œæ¥ç€æˆ‘ä»¬å°±å¯ä»¥è®¡ç®—é¢„æµ‹çš„è¾“å‡º$\hat{\mathbf{u}}_{j|i} = \mathbf{W}_{i,j} \, \mathbf{u}_i$ï¼ˆè®ºæ–‡ä¸­çš„å…¬å¼ï¼ˆ2ï¼‰çš„å³åŠéƒ¨åˆ†ï¼‰ã€‚ç”±äºæˆ‘ä»¬æƒ³è¦å°†8ç»´å‘é‡å˜å½¢ä¸º16ç»´å‘é‡ï¼Œå› æ­¤æ¯ä¸ªå˜æ¢å‘é‡$\mathbf{W}_{i,j}$å¿…é¡»å…·å¤‡(16, 8)å½¢çŠ¶ã€‚

# è¦ä¸ºæ¯å¯¹èƒ¶å›Š ($i$, $j$) è®¡ç®— $\hat{\mathbf{u}}_{j|i}$ï¼Œæˆ‘ä»¬ä¼šåˆ©ç”¨ `tf.matmul()` å‡½æ•°çš„ä¸€ä¸ªç‰¹ç‚¹ï¼šä½ å¯èƒ½çŸ¥é“å®ƒå¯ä»¥è®©ä½ è¿›è¡Œä¸¤ä¸ªçŸ©é˜µç›¸ä¹˜ï¼Œä½†ä½ å¯èƒ½ä¸çŸ¥é“å®ƒå¯ä»¥è®©ä½ è¿›è¡Œæ›´é«˜ç»´åº¦çš„æ•°ç»„ç›¸ä¹˜ã€‚å®ƒå°†è¿™äº›æ•°ç»„è§†ä½œä¸ºæ•°ç»„çŸ©é˜µï¼Œå¹¶ä¸”å®ƒä¼šæ‰§è¡Œæ¯é¡¹çš„çŸ©é˜µç›¸ä¹˜ã€‚ä¾‹å¦‚ï¼Œè®¾æœ‰ä¸¤ä¸ª4Dæ•°ç»„ï¼Œæ¯ä¸ªåŒ…å«2Ã—3ç½‘æ ¼çš„çŸ©é˜µã€‚ç¬¬ä¸€ä¸ªåŒ…å«çŸ©é˜µä¸ºï¼š$\mathbf{A}, \mathbf{B}, \mathbf{C}, \mathbf{D}, \mathbf{E}, \mathbf{F}$ï¼Œç¬¬äºŒä¸ªåŒ…å«çŸ©é˜µä¸ºï¼š$\mathbf{G}, \mathbf{H}, \mathbf{I}, \mathbf{J}, \mathbf{K}, \mathbf{L}$ã€‚å¦‚æœä½ ä½¿ç”¨ `tf.matmul`å‡½æ•° å¯¹è¿™ä¸¤ä¸ª4Dæ•°ç»„è¿›è¡Œç›¸ä¹˜ï¼Œä½ å°±ä¼šå¾—åˆ°ï¼š
# 
# $
# \pmatrix{
# \mathbf{A} & \mathbf{B} & \mathbf{C} \\
# \mathbf{D} & \mathbf{E} & \mathbf{F}
# } \times
# \pmatrix{
# \mathbf{G} & \mathbf{H} & \mathbf{I} \\
# \mathbf{J} & \mathbf{K} & \mathbf{L}
# } = \pmatrix{
# \mathbf{AG} & \mathbf{BH} & \mathbf{CI} \\
# \mathbf{DJ} & \mathbf{EK} & \mathbf{FL}
# }
# $

# æˆ‘ä»¬å¯ä»¥æŠŠè¿™ä¸ªå‡½æ•°ç”¨æ¥è®¡ç®—æ¯å¯¹èƒ¶å›Š ($i$, $j$) çš„ $\hat{\mathbf{u}}_{j|i}$ï¼Œå°±åƒè¿™æ ·ï¼ˆå›å¿†ä¸€ä¸‹ï¼Œæœ‰ 6Ã—6Ã—32=1152 ä¸ªèƒ¶å›Šåœ¨ç¬¬ä¸€å±‚ï¼Œè¿˜æœ‰10ä¸ªåœ¨ç¬¬äºŒå±‚ï¼‰ï¼š
# 
# $
# \pmatrix{
#   \mathbf{W}_{1,1} & \mathbf{W}_{1,2} & \cdots & \mathbf{W}_{1,10} \\
#   \mathbf{W}_{2,1} & \mathbf{W}_{2,2} & \cdots & \mathbf{W}_{2,10} \\
#   \vdots & \vdots & \ddots & \vdots \\
#   \mathbf{W}_{1152,1} & \mathbf{W}_{1152,2} & \cdots & \mathbf{W}_{1152,10}
# } \times
# \pmatrix{
#   \mathbf{u}_1 & \mathbf{u}_1 & \cdots & \mathbf{u}_1 \\
#   \mathbf{u}_2 & \mathbf{u}_2 & \cdots & \mathbf{u}_2 \\
#   \vdots & \vdots & \ddots & \vdots \\
#   \mathbf{u}_{1152} & \mathbf{u}_{1152} & \cdots & \mathbf{u}_{1152}
# }
# =
# \pmatrix{
# \hat{\mathbf{u}}_{1|1} & \hat{\mathbf{u}}_{2|1} & \cdots & \hat{\mathbf{u}}_{10|1} \\
# \hat{\mathbf{u}}_{1|2} & \hat{\mathbf{u}}_{2|2} & \cdots & \hat{\mathbf{u}}_{10|2} \\
# \vdots & \vdots & \ddots & \vdots \\
# \hat{\mathbf{u}}_{1|1152} & \hat{\mathbf{u}}_{2|1152} & \cdots & \hat{\mathbf{u}}_{10|1152}
# }
# $
# 

# ç¬¬ä¸€ä¸ªæ•°ç»„çš„å½¢çŠ¶ä¸º (1152, 10, 16, 8)ï¼Œç¬¬äºŒä¸ªæ•°ç»„çš„å½¢çŠ¶ä¸º (1152, 10, 8, 1)ã€‚æ³¨æ„åˆ°ç¬¬äºŒä¸ªæ•°ç»„å¿…é¡»åŒ…å«10ä¸ªå¯¹äºå‘é‡$\mathbf{u}_1$ åˆ° $\mathbf{u}_{1152}$ çš„å®Œå…¨æ‹·è´ã€‚ä¸ºäº†è¦åˆ›å»ºè¿™æ ·çš„æ•°ç»„ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¥½ç”¨çš„ `tf.tile()` å‡½æ•°ï¼Œå®ƒå¯ä»¥è®©ä½ åˆ›å»ºåŒ…å«å¾ˆå¤šåŸºæ•°ç»„æ‹·è´çš„æ•°ç»„ï¼Œå¹¶ä¸”æ ¹æ®ä½ æƒ³è¦çš„è¿›è¡Œå¹³é“ºã€‚

# å“¦ï¼Œç¨ç­‰ï¼æˆ‘ä»¬è¿˜å¿˜äº†ä¸€ä¸ªç»´åº¦ï¼š_batch sizeï¼ˆæ‰¹é‡/æ‰¹æ¬¡çš„å¤§å°ï¼‰_ã€‚å‡è®¾æˆ‘ä»¬è¦ç»™èƒ¶å›Šç½‘ç»œæä¾›50å¼ å›¾ç‰‡ï¼Œé‚£ä¹ˆè¯¥ç½‘ç»œéœ€è¦åŒæ—¶ä½œå‡ºè¿™50å¼ å›¾ç‰‡çš„é¢„æµ‹ã€‚æ‰€ä»¥ç¬¬ä¸€ä¸ªæ•°ç»„çš„å½¢çŠ¶ä¸º (50, 1152, 10, 16, 8)ï¼Œè€Œç¬¬äºŒä¸ªæ•°ç»„çš„å½¢çŠ¶ä¸º (50, 1152, 10, 8, 1)ã€‚ç¬¬ä¸€å±‚çš„èƒ¶å›Šå®é™…ä¸Šå·²ç»å¯¹äºæ‰€æœ‰çš„50å¼ å›¾åƒä½œå‡ºé¢„æµ‹ï¼Œæ‰€ä»¥ç¬¬äºŒä¸ªæ•°ç»„æ²¡æœ‰é—®é¢˜ï¼Œä½†å¯¹äºç¬¬ä¸€ä¸ªæ•°ç»„ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ `tf.tile()` è®©å…¶å…·æœ‰50ä¸ªæ‹·è´çš„å˜æ¢çŸ©é˜µã€‚

# å¥½äº†ï¼Œè®©æˆ‘ä»¬å¼€å§‹ï¼Œåˆ›å»ºä¸€ä¸ªå¯è®­ç»ƒçš„å˜é‡ï¼Œå½¢çŠ¶ä¸º (1, 1152, 10, 16, 8) å¯ä»¥ç”¨æ¥æŒæœ‰æ‰€æœ‰çš„å˜æ¢çŸ©é˜µã€‚ç¬¬ä¸€ä¸ªç»´åº¦çš„å¤§å°ä¸º1ï¼Œå¯ä»¥è®©è¿™ä¸ªæ•°ç»„æ›´å®¹æ˜“çš„å¹³é“ºã€‚æˆ‘ä»¬ä½¿ç”¨æ ‡å‡†å·®ä¸º0.1çš„å¸¸è§„åˆ†å¸ƒï¼Œéšæœºåˆå§‹åŒ–è¿™ä¸ªå˜é‡ã€‚

# In[94]:


init_sigma = 0.1

W_init = tf.random_normal(
    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),
    stddev=init_sigma, dtype=tf.float32, name="W_init")
W = tf.Variable(W_init, name="W")


# ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡æ¯ä¸ªå®ä¾‹é‡å¤ä¸€æ¬¡`W`æ¥åˆ›å»ºç¬¬ä¸€ä¸ªæ•°ç»„ï¼š

# In[95]:


batch_size = tf.shape(X)[0]
W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name="W_tiled")


# å°±æ˜¯è¿™æ ·ï¼ç°åœ¨è½¬åˆ°ç¬¬äºŒä¸ªæ•°ç»„ã€‚å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªæ•°ç»„ï¼Œå½¢çŠ¶ä¸º (_batch size_, 1152, 10, 8, 1)ï¼ŒåŒ…å«ç¬¬ä¸€å±‚èƒ¶å›Šçš„è¾“å‡ºï¼Œé‡å¤10æ¬¡ï¼ˆä¸€æ¬¡ä¸€ä¸ªæ•°å­—ï¼Œåœ¨ç¬¬ä¸‰ä¸ªç»´åº¦ï¼Œå³axis=2ï¼‰ã€‚ `caps1_output` æ•°ç»„çš„å½¢çŠ¶ä¸º (_batch size_, 1152, 8)ï¼Œæ‰€ä»¥æˆ‘ä»¬é¦–å…ˆéœ€è¦å±•å¼€ä¸¤æ¬¡æ¥è·å¾—å½¢çŠ¶ (_batch size_, 1152, 1, 8, 1) çš„æ•°ç»„ï¼Œæ¥ç€åœ¨ç¬¬ä¸‰ç»´åº¦é‡å¤å®ƒ10æ¬¡ã€‚

# In[96]:


caps1_output_expanded = tf.expand_dims(caps1_output, -1,
                                       name="caps1_output_expanded")
caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,
                                   name="caps1_output_tile")
caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],
                             name="caps1_output_tiled")


# è®©æˆ‘ä»¬æ£€æŸ¥ä»¥ä¸‹ç¬¬ä¸€ä¸ªæ•°ç»„çš„å½¢çŠ¶ï¼š

# In[97]:


W_tiled


# å¾ˆå¥½ï¼Œç°åœ¨ç¬¬äºŒä¸ªï¼š

# In[98]:


caps1_output_tiled


# å¥½ï¼ç°åœ¨ï¼Œä¸ºäº†è¦è·å¾—æ‰€æœ‰çš„é¢„æµ‹å¥½çš„è¾“å‡ºå‘é‡ $\hat{\mathbf{u}}_{j|i}$ï¼Œæˆ‘ä»¬åªéœ€è¦å°†è¿™ä¸¤ä¸ªæ•°ç»„ä½¿ç”¨`tf.malmul()`å‡½æ•°è¿›è¡Œç›¸ä¹˜ï¼Œå°±åƒå‰é¢è§£é‡Šçš„é‚£æ ·ï¼š

# In[99]:


caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,
                            name="caps2_predicted")


# è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹å½¢çŠ¶ï¼š

# In[100]:


caps2_predicted


# éå¸¸å¥½ï¼Œå¯¹äºåœ¨è¯¥æ‰¹æ¬¡ï¼ˆæˆ‘ä»¬è¿˜ä¸çŸ¥é“æ‰¹æ¬¡çš„å¤§å°ï¼Œä½¿ç”¨ "?" æ›¿ä»£ï¼‰ä¸­çš„æ¯ä¸ªå®ä¾‹ä»¥åŠå¯¹äºæ¯å¯¹ç¬¬ä¸€å’Œç¬¬äºŒå±‚çš„èƒ¶å›Šï¼ˆ1152Ã—10ï¼‰ï¼Œæˆ‘ä»¬éƒ½æœ‰ä¸€ä¸ª16Dé¢„æµ‹çš„è¾“å‡ºåˆ—å‘é‡ (16Ã—1)ã€‚æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½åº”ç”¨ æ ¹æ®åè®®ç®—æ³•çš„è·¯ç”± äº†ï¼

# ## æ ¹æ®åè®®çš„è·¯ç”±

# é¦–å…ˆï¼Œè®©æˆ‘ä»¬åˆå§‹åŒ–åŸå§‹çš„è·¯ç”±æƒé‡ $b_{i,j}$ åˆ°0:

# In[101]:


raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],
                       dtype=np.float32, name="raw_weights")


# æˆ‘ä»¬é©¬ä¸Šå°†ä¼šçœ‹åˆ°ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦æœ€åä¸¤ç»´å¤§å°ä¸º1çš„ç»´åº¦ã€‚

# ### ç¬¬ä¸€è½®

# é¦–å…ˆï¼Œè®©æˆ‘ä»¬åº”ç”¨ sofmax å‡½æ•°æ¥è®¡ç®—è·¯ç”±æƒé‡ï¼Œ$\mathbf{c}_{i} = \operatorname{softmax}(\mathbf{b}_i)$ ï¼ˆè®ºæ–‡ä¸­çš„å…¬å¼ï¼ˆ3ï¼‰ï¼‰ï¼š

# In[102]:


routing_weights = tf.nn.softmax(raw_weights, dim=2, name="routing_weights")


# ç°åœ¨è®©æˆ‘ä»¬ä¸ºæ¯ä¸ªç¬¬äºŒå±‚èƒ¶å›Šè®¡ç®—å…¶é¢„æµ‹è¾“å‡ºå‘é‡çš„åŠ æƒï¼Œ$\mathbf{s}_j = \sum\limits_{i}{c_{i,j}\hat{\mathbf{u}}_{j|i}}$ ï¼ˆè®ºæ–‡å…¬å¼ï¼ˆ2ï¼‰çš„å·¦åŠéƒ¨åˆ†ï¼‰ï¼š

# In[103]:


weighted_predictions = tf.multiply(routing_weights, caps2_predicted,
                                   name="weighted_predictions")
weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,
                             name="weighted_sum")


# è¿™é‡Œæœ‰å‡ ä¸ªé‡è¦çš„ç»†èŠ‚éœ€è¦æ³¨æ„ï¼š
# * è¦æ‰§è¡Œå…ƒç´ çº§åˆ«çŸ©é˜µç›¸ä¹˜ï¼ˆä¹Ÿç§°ä¸ºHadamardç§¯ï¼Œè®°ä½œ$\circ$ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨`tf.multiply()` å‡½æ•°ã€‚å®ƒè¦æ±‚  `routing_weights` å’Œ `caps2_predicted` å…·æœ‰ç›¸åŒçš„ç§©ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå‰é¢æˆ‘ä»¬åœ¨ `routing_weights` ä¸Šæ·»åŠ äº†ä¸¤ä¸ªé¢å¤–çš„ç»´åº¦ã€‚
# * `routing_weights`çš„å½¢çŠ¶ä¸º (_batch size_, 1152, 10, 1, 1) è€Œ `caps2_predicted` çš„å½¢çŠ¶ä¸º (_batch size_, 1152, 10, 16, 1)ã€‚ç”±äºå®ƒä»¬åœ¨ç¬¬å››ä¸ªç»´åº¦ä¸Šä¸åŒ¹é…ï¼ˆ1 _vs_ 16ï¼‰ï¼Œ`tf.multiply()` è‡ªåŠ¨åœ°åœ¨ `routing_weights` è¯¥ç»´åº¦ä¸Š _å¹¿æ’­_ äº†16æ¬¡ã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰å¹¿æ’­ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œä¹Ÿè®¸å¯ä»¥å¸®ä¸Šå¿™ï¼š
# 
#   $ \pmatrix{1 & 2 & 3 \\ 4 & 5 & 6} \circ \pmatrix{10 & 100 & 1000} = \pmatrix{1 & 2 & 3 \\ 4 & 5 & 6} \circ \pmatrix{10 & 100 & 1000 \\ 10 & 100 & 1000} = \pmatrix{10 & 200 & 3000 \\ 40 & 500 & 6000} $

# æœ€åï¼Œè®©æˆ‘ä»¬åº”ç”¨squashå‡½æ•°åˆ°åœ¨åè®®ç®—æ³•çš„ç¬¬ä¸€æ¬¡è¿­ä»£è¿­ä»£ç»“æŸæ—¶è·å–ç¬¬äºŒå±‚èƒ¶å›Šçš„è¾“å‡ºä¸Šï¼Œ$\mathbf{v}_j = \operatorname{squash}(\mathbf{s}_j)$ï¼š

# In[104]:


caps2_output_round_1 = squash(weighted_sum, axis=-2,
                              name="caps2_output_round_1")


# In[105]:


caps2_output_round_1


# å¥½ï¼æˆ‘ä»¬å¯¹äºæ¯ä¸ªå®ä¾‹æœ‰äº†10ä¸ª16Dè¾“å‡ºå‘é‡ï¼Œå°±åƒæˆ‘ä»¬æœŸå¾…çš„é‚£æ ·ã€‚

# ### ç¬¬äºŒè½®

# é¦–å…ˆï¼Œè®©æˆ‘ä»¬è¡¡é‡ä¸€ä¸‹ï¼Œæ¯ä¸ªé¢„æµ‹å‘é‡ $\hat{\mathbf{u}}_{j|i}$ å¯¹äºå®é™…è¾“å‡ºå‘é‡ $\mathbf{v}_j$ ä¹‹é—´åˆ°åº•æœ‰å¤šæ¥è¿‘ï¼Œè¿™æ˜¯é€šè¿‡å®ƒä»¬çš„æ ‡é‡ä¹˜ç§¯ $\hat{\mathbf{u}}_{j|i} \cdot \mathbf{v}_j$æ¥å®Œæˆçš„ã€‚

# * å¿«é€Ÿæ•°å­¦ä¸Šçš„æç¤ºï¼šå¦‚æœ $\vec{a}$ and $\vec{b}$ æ˜¯é•¿åº¦ç›¸ç­‰çš„å‘é‡ï¼Œå¹¶ä¸” $\mathbf{a}$ å’Œ $\mathbf{b}$ æ˜¯ç›¸åº”çš„åˆ—å‘é‡ï¼ˆå¦‚ï¼Œåªæœ‰ä¸€åˆ—çš„çŸ©é˜µï¼‰ï¼Œé‚£ä¹ˆ $\mathbf{a}^T \mathbf{b}$ ï¼ˆå³ $\mathbf{a}$çš„è½¬ç½®å’Œ $\mathbf{b}$çš„çŸ©é˜µç›¸ä¹˜ï¼‰ä¸ºä¸€ä¸ª1Ã—1çš„çŸ©é˜µï¼ŒåŒ…å«ä¸¤ä¸ªå‘é‡$\vec{a}\cdot\vec{b}$çš„æ ‡é‡ç§¯ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸å°†å‘é‡è¡¨ç¤ºä¸ºåˆ—å‘é‡ï¼Œæ‰€ä»¥å½“æˆ‘ä»¬æ¢è®¨å…³äºè®¡ç®—æ ‡é‡ç§¯ $\hat{\mathbf{u}}_{j|i} \cdot \mathbf{v}_j$çš„æ—¶å€™ï¼Œå…¶å®æ„å‘³ç€è®¡ç®— ${\hat{\mathbf{u}}_{j|i}}^T \mathbf{v}_j$ã€‚

# ç”±äºæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªå®ä¾‹å’Œæ¯ä¸ªç¬¬ä¸€å’Œç¬¬äºŒå±‚çš„èƒ¶å›Šå¯¹$(i, j)$ï¼Œè®¡ç®—æ ‡é‡ç§¯ $\hat{\mathbf{u}}_{j|i} \cdot \mathbf{v}_j$ ï¼Œæˆ‘ä»¬å°†å†æ¬¡åˆ©ç”¨`tf.matmul()`å¯ä»¥åŒæ—¶è®¡ç®—å¤šä¸ªçŸ©é˜µç›¸ä¹˜çš„ç‰¹ç‚¹ã€‚è¿™å°±è¦æ±‚ä½¿ç”¨ `tf.tile()`æ¥ä½¿å¾—æ‰€æœ‰ç»´åº¦éƒ½åŒ¹é…ï¼ˆé™¤äº†å€’æ•°ç¬¬äºŒä¸ªï¼‰ï¼Œå°±åƒæˆ‘ä»¬ä¹‹å‰æ‰€ä½œçš„é‚£æ ·ã€‚æ‰€ä»¥è®©æˆ‘ä»¬æŸ¥çœ‹`caps2_predicted`çš„å½¢çŠ¶ï¼Œå› ä¸ºå®ƒæŒæœ‰å¯¹æ¯ä¸ªå®ä¾‹å’Œæ¯ä¸ªèƒ¶å›Šå¯¹çš„æ‰€æœ‰é¢„æµ‹è¾“å‡ºå‘é‡$\hat{\mathbf{u}}_{j|i}$ã€‚

# In[106]:


caps2_predicted


# ç°åœ¨è®©æˆ‘ä»¬æŸ¥çœ‹ `caps2_output_round_1` çš„å½¢çŠ¶ï¼Œå®ƒæœ‰10ä¸ªè¾“å‡ºå‘é‡ï¼Œæ¯ä¸ª16Dï¼Œå¯¹åº”æ¯ä¸ªå®ä¾‹ï¼š

# In[107]:


caps2_output_round_1


# ä¸ºäº†è®©è¿™äº›å½¢çŠ¶ç›¸åŒ¹é…ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨ç¬¬äºŒä¸ªç»´åº¦å¹³é“º `caps2_output_round_1` 1152æ¬¡ï¼ˆä¸€æ¬¡ä¸€ä¸ªä¸»èƒ¶å›Šï¼‰ï¼š

# In[108]:


caps2_output_round_1_tiled = tf.tile(
    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],
    name="caps2_output_round_1_tiled")


# ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½å¯ä»¥è°ƒç”¨ `tf.matmul()`ï¼ˆæ³¨æ„è¿˜éœ€è¦å‘ŠçŸ¥å®ƒåœ¨ç¬¬ä¸€ä¸ªæ•°ç»„ä¸­çš„çŸ©é˜µè¿›è¡Œè½¬ç½®ï¼Œè®©${\hat{\mathbf{u}}_{j|i}}^T$ æ¥æ›¿ä»£ $\hat{\mathbf{u}}_{j|i}$ï¼‰ï¼š

# In[109]:


agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,
                      transpose_a=True, name="agreement")


# æˆ‘ä»¬ç°åœ¨å¯ä»¥é€šè¿‡å¯¹äºåˆšè®¡ç®—çš„æ ‡é‡ç§¯$\hat{\mathbf{u}}_{j|i} \cdot \mathbf{v}_j$è¿›è¡Œç®€å•ç›¸åŠ ï¼Œæ¥è¿›è¡ŒåŸå§‹è·¯ç”±æƒé‡ $b_{i,j}$ çš„æ›´æ–°ï¼š$b_{i,j} \gets b_{i,j} + \hat{\mathbf{u}}_{j|i} \cdot \mathbf{v}_j$ ï¼ˆå‚è§è®ºæ–‡è¿‡ç¨‹1ä¸­ç¬¬7æ­¥ï¼‰

# In[110]:


raw_weights_round_2 = tf.add(raw_weights, agreement,
                             name="raw_weights_round_2")


# ç¬¬äºŒè½®çš„å…¶ä½™éƒ¨åˆ†å’Œç¬¬ä¸€è½®ç›¸åŒï¼š

# In[111]:


routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,
                                        dim=2,
                                        name="routing_weights_round_2")
weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,
                                           caps2_predicted,
                                           name="weighted_predictions_round_2")
weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,
                                     axis=1, keep_dims=True,
                                     name="weighted_sum_round_2")
caps2_output_round_2 = squash(weighted_sum_round_2,
                              axis=-2,
                              name="caps2_output_round_2")


# æˆ‘ä»¬å¯ä»¥ç»§ç»­æ›´å¤šè½®ï¼Œåªéœ€è¦é‡å¤ç¬¬äºŒè½®ä¸­ç›¸åŒçš„æ­¥éª¤ï¼Œä½†ä¸ºäº†ä¿æŒç®€æ´ï¼Œæˆ‘ä»¬å°±åˆ°è¿™é‡Œï¼š

# In[112]:


caps2_output = caps2_output_round_2


# ### é™æ€è¿˜æ˜¯åŠ¨æ€å¾ªç¯ï¼Ÿ

# åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬åœ¨TensorFlowè®¡ç®—å›¾ä¸­ä¸ºåè°ƒç®—æ³•çš„æ¯ä¸€è½®è·¯ç”±åˆ›å»ºäº†ä¸åŒçš„æ“ä½œã€‚æ¢å¥è¯è¯´ï¼Œå®ƒæ˜¯ä¸€ä¸ªé™æ€å¾ªç¯ã€‚
# 
# å½“ç„¶ï¼Œä¸å…¶æ‹·è´/ç²˜è´´è¿™äº›ä»£ç å‡ æ¬¡ï¼Œé€šå¸¸åœ¨pythonä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å†™ä¸€ä¸ª `for` å¾ªç¯ï¼Œä½†è¿™ä¸ä¼šæ”¹å˜è¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œé‚£å°±æ˜¯åœ¨è®¡ç®—å›¾ä¸­æœ€åå¯¹äºæ¯ä¸ªè·¯ç”±è¿­ä»£éƒ½ä¼šæœ‰ä¸åŒçš„æ“ä½œã€‚è¿™å…¶å®æ˜¯å¯æ¥å—çš„ï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸ä¸ä¼šå…·æœ‰è¶…è¿‡5æ¬¡è·¯ç”±è¿­ä»£ï¼Œæ‰€ä»¥è®¡ç®—å›¾ä¸ä¼šæˆé•¿å¾—å¤ªå¤§ã€‚
# 
# ç„¶è€Œï¼Œä½ å¯èƒ½æ›´å€¾å‘äºåœ¨TensorFlowè®¡ç®—å›¾è‡ªèº«å®ç°è·¯ç”±å¾ªç¯ï¼Œè€Œä¸æ˜¯ä½¿ç”¨Pythonçš„`for`å¾ªç¯ã€‚ä¸ºäº†è¦åšåˆ°è¿™ç‚¹ï¼Œå°†éœ€è¦ä½¿ç”¨TensorFlowçš„ `tf.while_loop()` å‡½æ•°ã€‚è¿™ç§æ–¹å¼ï¼Œæ‰€æœ‰çš„è·¯ç”±å¾ªç¯éƒ½å¯ä»¥é‡ç”¨åœ¨è¯¥è®¡ç®—å›¾ä¸­çš„ç›¸åŒçš„æ“ä½œï¼Œè¿™è¢«ç§°ä¸ºåŠ¨æ€å¾ªç¯ã€‚
# 
# ä¾‹å¦‚ï¼Œè¿™é‡Œæ˜¯å¦‚ä½•æ„å»ºä¸€ä¸ªå°å¾ªç¯ç”¨æ¥è®¡ç®—1åˆ°100çš„å¹³æ–¹å’Œï¼š

# In[113]:


def condition(input, counter):
    return tf.less(counter, 100)

def loop_body(input, counter):
    output = tf.add(input, tf.square(counter))
    return output, tf.add(counter, 1)

with tf.name_scope("compute_sum_of_squares"):
    counter = tf.constant(1)
    sum_of_squares = tf.constant(0)

    result = tf.while_loop(condition, loop_body, [sum_of_squares, counter])
    

with tf.Session() as sess:
    print(sess.run(result))


# å¦‚ä½ æ‰€è§ï¼Œ `tf.while_loop()` å‡½æ•°æœŸæœ›çš„å¾ªç¯æ¡ä»¶å’Œå¾ªç¯ä½“ç”±ä¸¤ä¸ªå‡½æ•°æ¥æä¾›ã€‚è¿™äº›å‡½æ•°ä»…ä¼šè¢«TensorFlowè°ƒç”¨ä¸€æ¬¡ï¼Œåœ¨æ„å»ºè®¡ç®—å›¾é˜¶æ®µï¼Œ_ä¸_ åœ¨æ‰§è¡Œè®¡ç®—å›¾çš„æ—¶å€™ã€‚ `tf.while_loop()` å‡½æ•°å°†ç”± `condition()` å’Œ `loop_body()` åˆ›å»ºçš„è®¡ç®—å›¾ç¢ç‰‡åŒä¸€äº›ç”¨æ¥åˆ›å»ºå¾ªç¯çš„é¢å¤–æ“ä½œç¼åˆ¶åœ¨ä¸€èµ·ã€‚
# 
# è¿˜æ³¨æ„åˆ°åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼ŒTensorFlowå°†è‡ªåŠ¨åœ°é€šè¿‡å¾ªç¯å¤„ç†åå‘ä¼ æ’­ï¼Œå› æ­¤ä½ ä¸éœ€è¦æ‹…å¿ƒè¿™äº›äº‹æƒ…ã€‚

# å½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä¸€è¡Œä»£ç æå®šï¼;)

# In[ ]:


sum([i**2 for i in range(1, 100 + 1)])


# å¼€ä¸ªç©ç¬‘ï¼ŒæŠ›å¼€ç¼©å‡è®¡ç®—å›¾çš„å¤§å°ä¸è¯´ï¼Œä½¿ç”¨åŠ¨æ€å¾ªç¯è€Œä¸æ˜¯é™æ€å¾ªç¯èƒ½å¤Ÿå¸®åŠ©å‡å°‘å¾ˆå¤šçš„GPU RAMçš„ä½¿ç”¨ï¼ˆå¦‚æœä½ ä½¿ç”¨GPUçš„è¯ï¼‰ã€‚äº‹å®ä¸Šï¼Œå¦‚æœä½†è°ƒç”¨ `tf.while_loop()` å‡½æ•°æ—¶ï¼Œä½ è®¾ç½®äº† `swap_memory=True` ï¼ŒTensorFlowä¼šåœ¨æ¯ä¸ªå¾ªç¯çš„è¿­ä»£ä¸Šè‡ªåŠ¨æ£€æŸ¥GPU RAMä½¿ç”¨æƒ…å†µï¼Œå¹¶ä¸”å®ƒä¼šç…§é¡¾åˆ°åœ¨GPUå’ŒCPUä¹‹é—´swappingå†…å­˜æ—¶çš„éœ€æ±‚ã€‚æ—¢ç„¶CPUçš„å†…å­˜ä¾¿å®œé‡åˆå¤§ï¼Œç›¸å¯¹GPU RAMè€Œè¨€ï¼Œè¿™å°±å¾ˆæœ‰æ„ä¹‰äº†ã€‚

# # ä¼°ç®—çš„åˆ†ç±»æ¦‚ç‡ï¼ˆæ¨¡é•¿ï¼‰

# è¾“å‡ºå‘é‡çš„æ¨¡é•¿ä»£è¡¨äº†åˆ†ç±»çš„æ¦‚ç‡ï¼Œæ‰€ä»¥æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨`tf.norm()`æ¥è®¡ç®—å®ƒä»¬ï¼Œä½†ç”±äºæˆ‘ä»¬åœ¨è®¨è®º`squash`å‡½æ•°æ—¶çœ‹åˆ°çš„é‚£æ ·ï¼Œå¯èƒ½ä¼šæœ‰é£é™©ï¼Œæ‰€ä»¥æˆ‘ä»¬åˆ›å»ºäº†è‡ªå·±çš„ `safe_norm()` å‡½æ•°æ¥è¿›è¡Œæ›¿ä»£ï¼š

# In[114]:


def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):
    with tf.name_scope(name, default_name="safe_norm"):
        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,
                                     keep_dims=keep_dims)
        return tf.sqrt(squared_norm + epsilon)


# In[115]:


y_proba = safe_norm(caps2_output, axis=-2, name="y_proba")


# è¦é¢„æµ‹æ¯ä¸ªå®ä¾‹çš„åˆ†ç±»ï¼Œæˆ‘ä»¬åªéœ€è¦é€‰æ‹©é‚£ä¸ªå…·æœ‰æœ€é«˜ä¼°ç®—æ¦‚ç‡çš„å°±å¯ä»¥äº†ã€‚è¦åšåˆ°è¿™ç‚¹ï¼Œè®©æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ `tf.argmax()` æ¥è¾¾åˆ°æˆ‘ä»¬çš„ç›®çš„ï¼š

# In[116]:


y_proba_argmax = tf.argmax(y_proba, axis=2, name="y_proba")


# è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹ `y_proba_argmax` çš„å½¢çŠ¶ï¼š

# In[117]:


y_proba_argmax


# è¿™æ­£å¥½æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼šå¯¹äºæ¯ä¸€ä¸ªå®ä¾‹ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰äº†æœ€é•¿çš„è¾“å‡ºå‘é‡çš„ç´¢å¼•ã€‚è®©æˆ‘ä»¬ç”¨ `tf.squeeze()` æ¥ç§»é™¤åä¸¤ä¸ªå¤§å°ä¸º1çš„ç»´åº¦ã€‚è¿™å°±ç»™å‡ºäº†è¯¥èƒ¶å›Šç½‘ç»œå¯¹äºæ¯ä¸ªå®ä¾‹çš„é¢„æµ‹åˆ†ç±»ï¼š

# In[118]:


y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name="y_pred")


# In[119]:


y_pred


# å¥½äº†ï¼Œæˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½å¼€å§‹å®šä¹‰è®­ç»ƒæ“ä½œï¼Œä»æŸå¤±å¼€å§‹ã€‚

# # æ ‡ç­¾

# é¦–å…ˆï¼Œæˆ‘ä»¬å°†éœ€è¦ä¸€ä¸ªå¯¹äºæ ‡ç­¾çš„å ä½ç¬¦ï¼š

# In[120]:


y = tf.placeholder(shape=[None], dtype=tf.int64, name="y")


# # è¾¹é™…æŸå¤±

# è®ºæ–‡ä½¿ç”¨äº†ä¸€ä¸ªç‰¹æ®Šçš„è¾¹é™…æŸå¤±ï¼Œæ¥ä½¿å¾—åœ¨æ¯ä¸ªå›¾åƒä¸­ä¾¦æµ‹å¤šäºä¸¤ä¸ªä»¥ä¸Šçš„æ•°å­—æˆä¸ºå¯èƒ½ï¼š
# 
# $ L_k = T_k \max(0, m^{+} - \|\mathbf{v}_k\|)^2 + \lambda (1 - T_k) \max(0, \|\mathbf{v}_k\| - m^{-})^2$
# 
# * $T_k$ ç­‰äº1ï¼Œå¦‚æœåˆ†ç±»$k$çš„æ•°å­—å‡ºç°ï¼Œå¦åˆ™ä¸º0.
# * åœ¨è®ºæ–‡ä¸­ï¼Œ$m^{+} = 0.9$, $m^{-} = 0.1$ï¼Œå¹¶ä¸”$\lambda = 0.5$
# * æ³¨æ„åœ¨è§†é¢‘15:47ç§’å¤„æœ‰ä¸ªé”™è¯¯ï¼šåº”è¯¥æ˜¯æœ€å¤§åŒ–æ“ä½œï¼Œè€Œä¸æ˜¯normsï¼Œè¢«å¹³æ–¹ã€‚ä¸å¥½æ„æ€ã€‚

# In[121]:


m_plus = 0.9
m_minus = 0.1
lambda_ = 0.5


# æ—¢ç„¶ `y` å°†åŒ…å«æ•°å­—åˆ†ç±»ï¼Œä»0åˆ°9ï¼Œè¦å¯¹äºæ¯ä¸ªå®ä¾‹å’Œæ¯ä¸ªåˆ†ç±»è·å– $T_k$ ï¼Œæˆ‘ä»¬åªéœ€è¦ä½¿ç”¨ `tf.one_hot()` å‡½æ•°å³å¯ï¼š

# In[122]:


T = tf.one_hot(y, depth=caps2_n_caps, name="T")


# ä¸€ä¸ªå°ä¾‹å­åº”è¯¥å¯ä»¥è¯´æ˜è¿™åˆ°åº•åšäº†ä»€ä¹ˆï¼š

# In[123]:


with tf.Session():
    print(T.eval(feed_dict={y: np.array([0, 1, 2, 3, 9])}))


# ç°åœ¨è®©æˆ‘ä»¬å¯¹äºæ¯ä¸ªè¾“å‡ºèƒ¶å›Šå’Œæ¯ä¸ªå®ä¾‹è®¡ç®—è¾“å‡ºå‘é‡ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬éªŒè¯ `caps2_output` å½¢çŠ¶ï¼š

# In[124]:


caps2_output


# è¿™äº›16Då‘é‡ä½äºç¬¬äºŒåˆ°æœ€åçš„ç»´åº¦ï¼Œå› æ­¤è®©æˆ‘ä»¬åœ¨ `axis=-2` ä½¿ç”¨ `safe_norm()` å‡½æ•°ï¼š

# In[125]:


caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,
                              name="caps2_output_norm")


# ç°åœ¨è®©æˆ‘ä»¬è®¡ç®— $\max(0, m^{+} - \|\mathbf{v}_k\|)^2$ï¼Œå¹¶ä¸”é‡å¡‘å…¶ç»“æœä»¥è·å¾—ä¸€ä¸ªç®€å•çš„å…·æœ‰å½¢çŠ¶(_batch size_, 10)çš„çŸ©é˜µï¼š

# In[126]:


present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),
                              name="present_error_raw")
present_error = tf.reshape(present_error_raw, shape=(-1, 10),
                           name="present_error")


# æ¥ä¸‹æ¥è®©æˆ‘ä»¬è®¡ç®— $\max(0, \|\mathbf{v}_k\| - m^{-})^2$ å¹¶ä¸”é‡å¡‘æˆ(_batch size_,10)ï¼š

# In[127]:


absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),
                             name="absent_error_raw")
absent_error = tf.reshape(absent_error_raw, shape=(-1, 10),
                          name="absent_error")


# æˆ‘ä»¬å‡†å¤‡å¥½ä¸ºæ¯ä¸ªå®ä¾‹å’Œæ¯ä¸ªæ•°å­—è®¡ç®—æŸå¤±ï¼š

# In[128]:


L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,
           name="L")


# ç°åœ¨æˆ‘ä»¬å¯ä»¥æŠŠå¯¹äºæ¯ä¸ªå®ä¾‹çš„æ•°å­—æŸå¤±è¿›è¡Œç›¸åŠ ($L_0 + L_1 + \cdots + L_9$)ï¼Œå¹¶ä¸”åœ¨æ‰€æœ‰çš„å®ä¾‹ä¸­è®¡ç®—å‡å€¼ã€‚è¿™ç»™äºˆæˆ‘ä»¬æœ€åçš„è¾¹é™…æŸå¤±ï¼š

# In[129]:


margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name="margin_loss")


# # é‡æ–°æ„é€ 

# ç°åœ¨è®©æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªè§£ç å™¨ç½‘ç»œï¼Œå…¶ä½äºèƒ¶å›Šç½‘ç»œä¹‹ä¸Šã€‚å®ƒæ˜¯ä¸€ä¸ªå¸¸è§„çš„3å±‚å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œå…¶å°†åŸºäºèƒ¶å›Šç½‘ç»œçš„è¾“å‡ºï¼Œå­¦ä¹ é‡æ–°æ„å»ºè¾“å…¥å›¾åƒã€‚è¿™å°†å¼ºåˆ¶èƒ¶å›Šç½‘ç»œä¿ç•™æ‰€æœ‰éœ€è¦é‡æ–°æ„é€ æ•°å­—çš„ä¿¡æ¯ï¼Œè´¯ç©¿æ•´ä¸ªç½‘ç»œã€‚è¯¥çº¦æŸæ­£åˆ™åŒ–äº†æ¨¡å‹ï¼šå®ƒå‡å°‘äº†è®­ç»ƒæ•°æ®é›†è¿‡æ‹Ÿåˆçš„é£é™©ï¼Œå¹¶ä¸”å®ƒæœ‰åŠ©äºæ³›åŒ–åˆ°æ–°çš„æ•°å­—ã€‚

# ## é®ç›–

# è®ºæ–‡ä¸­æåŠäº†åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œä¸å…¶å‘é€æ‰€æœ‰çš„èƒ¶å›Šç½‘ç»œçš„è¾“å‡ºåˆ°è§£ç å™¨ç½‘ç»œï¼Œä¸å¦‚ä»…å‘é€ä¸ç›®æ ‡æ•°å­—å¯¹åº”çš„èƒ¶å›Šè¾“å‡ºå‘é‡ã€‚æ‰€æœ‰å…¶ä½™è¾“å‡ºå‘é‡å¿…é¡»è¢«é®ç›–æ‰ã€‚åœ¨æ¨æ–­çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¿…é¡»é®ç›–æ‰€æœ‰è¾“å‡ºå‘é‡ï¼Œé™¤äº†æœ€é•¿çš„é‚£ä¸ªã€‚å³ï¼Œé¢„æµ‹çš„æ•°å­—ç›¸å…³çš„é‚£ä¸ªã€‚ä½ å¯ä»¥æŸ¥çœ‹è®ºæ–‡ä¸­çš„å›¾2ï¼ˆè§†é¢‘ä¸­çš„18:15ï¼‰ï¼šæ‰€æœ‰çš„è¾“å‡ºå‘é‡éƒ½è¢«é®ç›–æ‰äº†ï¼Œé™¤äº†é‚£ä¸ªé‡æ–°æ„é€ ç›®æ ‡çš„è¾“å‡ºå‘é‡ã€‚

# æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå ä½ç¬¦æ¥å‘Šè¯‰TensorFlowï¼Œæ˜¯å¦æˆ‘ä»¬æƒ³è¦é®ç›–è¿™äº›è¾“å‡ºå‘é‡ï¼Œæ ¹æ®æ ‡ç­¾ (`True`) æˆ– é¢„æµ‹ (`False`, é»˜è®¤)ï¼š

# In[130]:


mask_with_labels = tf.placeholder_with_default(False, shape=(),
                                               name="mask_with_labels")


# ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨ `tf.cond()` æ¥å®šä¹‰é‡æ–°æ„é€ çš„ç›®æ ‡ï¼Œå¦‚æœ `mask_with_labels` ä¸º `True` å°±æ˜¯æ ‡ç­¾ `y`ï¼Œå¦åˆ™å°±æ˜¯ `y_pred`ã€‚

# In[131]:


reconstruction_targets = tf.cond(mask_with_labels, # æ¡ä»¶
                                 lambda: y,        # if True
                                 lambda: y_pred,   # if False
                                 name="reconstruction_targets")


# æ³¨æ„åˆ° `tf.cond()` å‡½æ•°æœŸæœ›çš„æ˜¯é€šè¿‡å‡½æ•°ä¼ é€’è€Œæ¥çš„if-True å’Œ if-Falseå¼ é‡ï¼šè¿™äº›å‡½æ•°ä¼šåœ¨è®¡ç®—å›¾æ„é€ é˜¶æ®µï¼ˆè€Œéæ‰§è¡Œé˜¶æ®µï¼‰è¢«ä»…è°ƒç”¨ä¸€æ¬¡ï¼Œå’Œ`tf.while_loop()`ç±»ä¼¼ã€‚è¿™å¯ä»¥å…è®¸TensorFlowæ·»åŠ å¿…è¦æ“ä½œï¼Œä»¥æ­¤å¤„ç†if-True å’Œ if-False å¼ é‡çš„æ¡ä»¶è¯„ä¼°ã€‚ç„¶è€Œï¼Œåœ¨è¿™é‡Œï¼Œå¼ é‡ `y` å’Œ `y_pred` å·²ç»åœ¨æˆ‘ä»¬è°ƒç”¨ `tf.cond()` æ—¶è¢«åˆ›å»ºï¼Œä¸å¹¸åœ°æ˜¯TensorFlowä¼šè®¤ä¸º `y` å’Œ `y_pred` æ˜¯ `reconstruction_targets` å¼ é‡çš„ä¾èµ–é¡¹ã€‚è™½ç„¶ï¼Œ`reconstruction_targets` å¼ é‡æœ€ç»ˆæ˜¯ä¼šè®¡ç®—å‡ºæ­£ç¡®å€¼ï¼Œä½†æ˜¯ï¼š
# 1. æ— è®ºä½•æ—¶ï¼Œæˆ‘ä»¬è¯„ä¼°æŸä¸ªä¾èµ–äº `reconstruction_targets` çš„å¼ é‡ï¼Œ`y_pred` å¼ é‡ä¹Ÿä¼šè¢«è¯„ä¼°ï¼ˆå³ä¾¿ `mask_with_layers` ä¸º `True`ï¼‰ã€‚è¿™ä¸æ˜¯ä»€ä¹ˆå¤§é—®é¢˜ï¼Œå› ä¸ºï¼Œåœ¨è®­ç»ƒé˜¶æ®µè®¡ç®—`y_pred` å¼ é‡ä¸ä¼šæ·»åŠ é¢å¤–çš„å¼€é”€ï¼Œè€Œä¸”ä¸ç®¡æ€ä¹ˆæ ·æˆ‘ä»¬éƒ½éœ€è¦å®ƒæ¥è®¡ç®—è¾¹é™…æŸå¤±ã€‚å¹¶ä¸”åœ¨æµ‹è¯•ä¸­ï¼Œå¦‚æœæˆ‘ä»¬åšçš„æ˜¯åˆ†ç±»ï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦é‡æ–°æ„é€ ï¼Œæ‰€ä»¥`reconstruction_grpha`æ ¹æœ¬ä¸ä¼šè¢«è¯„ä¼°ã€‚
# 2. æˆ‘ä»¬æ€»æ˜¯éœ€è¦ä¸º`y`å ä½ç¬¦é€’é€ä¸€ä¸ªå€¼ï¼ˆå³ä½¿`mask_with_layers`ä¸º`False`ï¼‰ã€‚è¿™å°±æœ‰ç‚¹è®¨åŒäº†ï¼Œå½“ç„¶æˆ‘ä»¬å¯ä»¥ä¼ é€’ä¸€ä¸ªç©ºæ•°ç»„ï¼Œå› ä¸ºTensorFlowæ— è®ºå¦‚ä½•éƒ½ä¸ä¼šç”¨åˆ°å®ƒï¼ˆå°±æ˜¯å½“æ£€æŸ¥ä¾èµ–é¡¹çš„æ—¶å€™è¿˜ä¸çŸ¥é“ï¼‰ã€‚

# ç°åœ¨æˆ‘ä»¬æœ‰äº†é‡æ–°æ„å»ºçš„ç›®æ ‡ï¼Œè®©æˆ‘ä»¬åˆ›å»ºé‡æ–°æ„å»ºçš„é®ç›–ã€‚å¯¹äºç›®æ ‡ç±»å‹å®ƒåº”è¯¥ä¸º1.0ï¼Œå¯¹äºå…¶ä»–ç±»å‹åº”è¯¥ä¸º0.0ã€‚ä¸ºæ­¤æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨`tf.one_hot()`å‡½æ•°ï¼š

# In[132]:


reconstruction_mask = tf.one_hot(reconstruction_targets,
                                 depth=caps2_n_caps,
                                 name="reconstruction_mask")


# è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹ `reconstruction_mask`çš„å½¢çŠ¶ï¼š

# In[133]:


reconstruction_mask


# å’Œ `caps2_output` çš„å½¢çŠ¶æ¯”å¯¹ä¸€ä¸‹ï¼š

# In[134]:


caps2_output


# å—¯ï¼Œå®ƒçš„å½¢çŠ¶æ˜¯ (_batch size_, 1, 10, 16, 1)ã€‚æˆ‘ä»¬æƒ³è¦å°†å®ƒå’Œ `reconstruction_mask` è¿›è¡Œç›¸ä¹˜ï¼Œä½† `reconstruction_mask`çš„å½¢çŠ¶æ˜¯(_batch size_, 10)ã€‚æˆ‘ä»¬å¿…é¡»å¯¹æ­¤è¿›è¡Œreshapeæˆ (_batch size_, 1, 10, 1, 1) æ¥æ»¡è¶³ç›¸ä¹˜çš„è¦æ±‚ï¼š

# In[135]:


reconstruction_mask_reshaped = tf.reshape(
    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],
    name="reconstruction_mask_reshaped")


# æœ€ç»ˆæˆ‘ä»¬å¯ä»¥åº”ç”¨ é®ç›– äº†ï¼

# In[136]:


caps2_output_masked = tf.multiply(
    caps2_output, reconstruction_mask_reshaped,
    name="caps2_output_masked")


# In[137]:


caps2_output_masked


# æœ€åè¿˜æœ‰ä¸€ä¸ªé‡å¡‘æ“ä½œè¢«ç”¨æ¥æ‰å¹³åŒ–è§£ç å™¨çš„è¾“å…¥ï¼š

# In[138]:


decoder_input = tf.reshape(caps2_output_masked,
                           [-1, caps2_n_caps * caps2_n_dims],
                           name="decoder_input")


# è¿™ç»™äºˆæˆ‘ä»¬ä¸€ä¸ªå½¢çŠ¶æ˜¯ (_batch size_, 160) çš„æ•°ç»„ï¼š

# In[139]:


decoder_input


# ## è§£ç å™¨

# ç°åœ¨è®©æˆ‘ä»¬æ¥æ„å»ºè¯¥è§£ç å™¨ã€‚å®ƒéå¸¸ç®€å•ï¼šä¸¤ä¸ªå¯†é›†ï¼ˆå…¨è¿æ¥ï¼‰ReLU å±‚ç´§è·Ÿè¿™ä¸€ä¸ªå¯†é›†è¾“å‡ºsigmoidå±‚ï¼š

# In[140]:


n_hidden1 = 512
n_hidden2 = 1024
n_output = 28 * 28


# In[141]:


with tf.name_scope("decoder"):
    hidden1 = tf.layers.dense(decoder_input, n_hidden1,
                              activation=tf.nn.relu,
                              name="hidden1")
    hidden2 = tf.layers.dense(hidden1, n_hidden2,
                              activation=tf.nn.relu,
                              name="hidden2")
    decoder_output = tf.layers.dense(hidden2, n_output,
                                     activation=tf.nn.sigmoid,
                                     name="decoder_output")


# ## é‡æ–°æ„é€ çš„æŸå¤±

# ç°åœ¨è®©æˆ‘ä»¬è®¡ç®—é‡æ–°æ„é€ çš„æŸå¤±ã€‚å®ƒä¸è¿‡æ˜¯è¾“å…¥å›¾åƒå’Œé‡æ–°æ„é€ è¿‡çš„å›¾åƒçš„å¹³æ–¹å·®ã€‚

# In[142]:


X_flat = tf.reshape(X, [-1, n_output], name="X_flat")
squared_difference = tf.square(X_flat - decoder_output,
                               name="squared_difference")
reconstruction_loss = tf.reduce_mean(squared_difference,
                                    name="reconstruction_loss")


# ## æœ€ç»ˆæŸå¤±

# æœ€ç»ˆæŸå¤±ä¸ºè¾¹é™…æŸå¤±å’Œé‡æ–°æ„é€ æŸå¤±ï¼ˆä½¿ç”¨æ”¾å¤§å› å­0.0005ç¡®ä¿è¾¹é™…æŸå¤±åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¤„äºæ”¯é…åœ°ä½ï¼‰çš„å’Œï¼š

# In[143]:


alpha = 0.0005

loss = tf.add(margin_loss, alpha * reconstruction_loss, name="loss")


# # æœ€åæ¶¦è‰²

# ## ç²¾åº¦

# ä¸ºäº†è¡¡é‡æ¨¡å‹çš„ç²¾åº¦ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å®ä¾‹è¢«æ­£ç¡®åˆ†ç±»çš„æ•°é‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°æ¯”è¾ƒ`y`å’Œ`y_pred`ï¼Œå¹¶å°†æ¯”è¾ƒç»“æœçš„å¸ƒå°”å€¼è½¬æ¢æˆfloat32ï¼ˆ0.0ä»£è¡¨Falseï¼Œ1.0ä»£è¡¨Trueï¼‰ï¼Œå¹¶ä¸”è®¡ç®—æ‰€æœ‰å®ä¾‹çš„å‡å€¼ï¼š

# In[144]:


correct = tf.equal(y, y_pred, name="correct")
accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name="accuracy")


# ## è®­ç»ƒæ“ä½œ

# è®ºæ–‡ä¸­æåˆ°ä½œè€…ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œä½¿ç”¨äº†TensorFlowçš„é»˜è®¤å‚æ•°ï¼š

# In[145]:


optimizer = tf.train.AdamOptimizer()
training_op = optimizer.minimize(loss, name="training_op")


# ## åˆå§‹åŒ–å’ŒSaver

# è®©æˆ‘ä»¬æ¥æ·»åŠ å˜é‡åˆå§‹å™¨ï¼Œè¿˜è¦åŠ ä¸€ä¸ª `Saver`ï¼š

# In[146]:


init = tf.global_variables_initializer()
saver = tf.train.Saver()


# è¿˜æœ‰... æˆ‘ä»¬å·²ç»å®Œæˆäº†æ„é€ é˜¶æ®µï¼èŠ±ç‚¹æ—¶é—´å¯ä»¥åº†ç¥ğŸ‰ä¸€ä¸‹ã€‚:)

# # è®­ç»ƒ

# è®­ç»ƒæˆ‘ä»¬çš„èƒ¶å›Šç½‘ç»œæ˜¯éå¸¸æ ‡å‡†çš„ã€‚ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä¸éœ€è¦ä½œä»»ä½•èŠ±å“¨çš„è¶…å‚è°ƒæ•´ã€ä¸¢å¼ƒç­‰ï¼Œæˆ‘ä»¬åªæ˜¯ä¸€éåˆä¸€éè¿è¡Œè®­ç»ƒæ“ä½œï¼Œæ˜¾ç¤ºæŸå¤±ï¼Œå¹¶ä¸”åœ¨æ¯ä¸ªepochç»“æŸçš„æ—¶å€™ï¼Œæ ¹æ®éªŒè¯é›†è¡¡é‡ä¸€ä¸‹ç²¾åº¦ï¼Œæ˜¾ç¤ºå‡ºæ¥ï¼Œå¹¶ä¸”ä¿å­˜æ¨¡å‹ï¼Œå½“ç„¶ï¼ŒéªŒè¯æŸå¤±æ˜¯ç›®å‰ä¸ºæ­¢æœ€ä½çš„æ¨¡å‹æ‰ä¼šè¢«ä¿å­˜ï¼ˆè¿™æ˜¯ä¸€ç§åŸºæœ¬çš„å®ç°æ—©åœçš„æ–¹æ³•ï¼Œè€Œä¸éœ€è¦å®é™…ä¸Šæ‰“æ–­è®­ç»ƒçš„è¿›ç¨‹ï¼‰ã€‚æˆ‘ä»¬å¸Œæœ›ä»£ç èƒ½å¤Ÿè‡ªé‡Šï¼Œä½†è¿™é‡Œåº”è¯¥æœ‰å‡ ä¸ªç»†èŠ‚å€¼å¾—æ³¨æ„ï¼š
# * å¦‚æœæŸä¸ªcheckpointæ–‡ä»¶å·²ç»å­˜åœ¨ï¼Œé‚£ä¹ˆå®ƒä¼šè¢«æ¢å¤ï¼ˆè¿™å¯ä»¥è®©è®­ç»ƒè¢«æ‰“æ–­ï¼Œå†ä»æœ€æ–°çš„checkpointä¸­è¿›è¡Œæ¢å¤æˆä¸ºå¯èƒ½ï¼‰ï¼Œ
# * æˆ‘ä»¬ä¸è¦å¿˜è®°åœ¨è®­ç»ƒçš„æ—¶å€™ä¼ é€’`mask_with_labels=True`ï¼Œ
# * åœ¨æµ‹è¯•çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è®©`mask_with_labels`é»˜è®¤ä¸º`False`ï¼ˆä½†æ˜¯æˆ‘ä»¬ä»ç„¶éœ€è¦ä¼ é€’æ ‡ç­¾ï¼Œå› ä¸ºå®ƒä»¬åœ¨è®¡ç®—ç²¾åº¦çš„æ—¶å€™ä¼šè¢«ç”¨åˆ°ï¼‰ï¼Œ
# * é€šè¿‡ `mnist.train.next_batch()`è£…è½½çš„å›¾ç‰‡ä¼šè¢«è¡¨ç¤ºä¸ºç±»å‹ `float32` æ•°ç»„ï¼Œå…¶å½¢çŠ¶ä¸º\[784\]ï¼Œä½†è¾“å…¥çš„å ä½ç¬¦`X`æœŸæœ›çš„æ˜¯ä¸€ä¸ª`float32`æ•°ç»„ï¼Œå…¶å½¢çŠ¶ä¸º \[28, 28, 1\]ï¼Œæ‰€ä»¥åœ¨æˆ‘ä»¬æŠŠé€åˆ°æ¨¡å‹ä¹‹å‰ï¼Œå¿…é¡»æŠŠè¿™äº›å›¾åƒè¿›è¡Œé‡å¡‘ï¼Œ
# * æˆ‘ä»¬åœ¨æ•´ä¸ªå®Œæ•´çš„éªŒè¯é›†ä¸Šå¯¹æ¨¡å‹çš„æŸå¤±å’Œç²¾åº¦è¿›è¡Œè¯„ä¼°ã€‚ä¸ºäº†èƒ½å¤Ÿçœ‹åˆ°è¿›åº¦å’Œæ”¯æŒé‚£äº›å¹¶æ²¡æœ‰å¤ªå¤šRAMçš„ç³»ç»Ÿï¼Œè¯„ä¼°æŸå¤±å’Œç²¾åº¦çš„ä»£ç åœ¨ä¸€ä¸ªæ‰¹æ¬¡ä¸Šæ‰§è¡Œä¸€æ¬¡ï¼Œå¹¶ä¸”æœ€åå†è®¡ç®—å¹³å‡æŸå¤±å’Œå¹³å‡ç²¾åº¦ã€‚
# 
# *è­¦å‘Š*ï¼šå¦‚æœä½ æ²¡æœ‰GPUï¼Œè®­ç»ƒå°†ä¼šéå¸¸æ¼«é•¿ï¼ˆè‡³å°‘å‡ ä¸ªå°æ—¶ï¼‰ã€‚å½“ä½¿ç”¨GPUï¼Œå®ƒåº”è¯¥å¯¹äºæ¯ä¸ªepochåªéœ€è¦å‡ åˆ†é’Ÿï¼ˆå¦‚ï¼Œåœ¨NVidia GeForce GTX 1080Tiä¸Šåªéœ€è¦6åˆ†é’Ÿï¼‰ã€‚

# In[147]:


n_epochs = 10
batch_size = 50
restore_checkpoint = True

n_iterations_per_epoch = mnist.train.num_examples // batch_size
n_iterations_validation = mnist.validation.num_examples // batch_size
best_loss_val = np.infty
checkpoint_path = "./my_capsule_network"

with tf.Session() as sess:
    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):
        saver.restore(sess, checkpoint_path)
    else:
        init.run()

    for epoch in range(n_epochs):
        for iteration in range(1, n_iterations_per_epoch + 1):
            X_batch, y_batch = mnist.train.next_batch(batch_size)
            # è¿è¡Œè®­ç»ƒæ“ä½œå¹¶ä¸”è¯„ä¼°æŸå¤±:
            _, loss_train = sess.run(
                [training_op, loss],
                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),
                           y: y_batch,
                           mask_with_labels: True})
            print("\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}".format(
                      iteration, n_iterations_per_epoch,
                      iteration * 100 / n_iterations_per_epoch,
                      loss_train),
                  end="")

        # åœ¨æ¯ä¸ªepochä¹‹åï¼Œ
        # è¡¡é‡éªŒè¯æŸå¤±å’Œç²¾åº¦ï¼š
        loss_vals = []
        acc_vals = []
        for iteration in range(1, n_iterations_validation + 1):
            X_batch, y_batch = mnist.validation.next_batch(batch_size)
            loss_val, acc_val = sess.run(
                    [loss, accuracy],
                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),
                               y: y_batch})
            loss_vals.append(loss_val)
            acc_vals.append(acc_val)
            print("\rEvaluating the model: {}/{} ({:.1f}%)".format(
                      iteration, n_iterations_validation,
                      iteration * 100 / n_iterations_validation),
                  end=" " * 10)
        loss_val = np.mean(loss_vals)
        acc_val = np.mean(acc_vals)
        print("\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}".format(
            epoch + 1, acc_val * 100, loss_val,
            " (improved)" if loss_val < best_loss_val else ""))

        # å¦‚æœæœ‰è¿›æ­¥å°±ä¿å­˜æ¨¡å‹ï¼š
        if loss_val < best_loss_val:
            save_path = saver.save(sess, checkpoint_path)
            best_loss_val = loss_val


# æˆ‘ä»¬åœ¨è®­ç»ƒç»“æŸåï¼Œåœ¨éªŒè¯é›†ä¸Šè¾¾åˆ°äº†99.32%çš„ç²¾åº¦ï¼Œåªç”¨äº†5ä¸ªepochesï¼Œçœ‹ä¸Šå»ä¸é”™ã€‚ç°åœ¨è®©æˆ‘ä»¬å°†æ¨¡å‹è¿ç”¨åˆ°æµ‹è¯•é›†ä¸Šã€‚

# # è¯„ä¼°

# In[148]:


n_iterations_test = mnist.test.num_examples // batch_size

with tf.Session() as sess:
    saver.restore(sess, checkpoint_path)

    loss_tests = []
    acc_tests = []
    for iteration in range(1, n_iterations_test + 1):
        X_batch, y_batch = mnist.test.next_batch(batch_size)
        loss_test, acc_test = sess.run(
                [loss, accuracy],
                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),
                           y: y_batch})
        loss_tests.append(loss_test)
        acc_tests.append(acc_test)
        print("\rEvaluating the model: {}/{} ({:.1f}%)".format(
                  iteration, n_iterations_test,
                  iteration * 100 / n_iterations_test),
              end=" " * 10)
    loss_test = np.mean(loss_tests)
    acc_test = np.mean(acc_tests)
    print("\rFinal test accuracy: {:.4f}%  Loss: {:.6f}".format(
        acc_test * 100, loss_test))


# æˆ‘ä»¬åœ¨æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº†99.21%çš„ç²¾åº¦ã€‚ç›¸å½“æ£’ï¼

# # é¢„æµ‹

# ç°åœ¨è®©æˆ‘ä»¬è¿›è¡Œä¸€äº›é¢„æµ‹ï¼é¦–å…ˆä»æµ‹è¯•é›†ç¡®å®šä¸€äº›å›¾ç‰‡ï¼Œæ¥ç€å¼€å§‹ä¸€ä¸ªsessionï¼Œæ¢å¤å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯„ä¼°`cap2_output`æ¥è·å¾—èƒ¶å›Šç½‘ç»œçš„è¾“å‡ºå‘é‡ï¼Œ`decoder_output`æ¥é‡æ–°æ„é€ ï¼Œç”¨`y_pred`æ¥è·å¾—ç±»å‹é¢„æµ‹ï¼š

# In[149]:


n_samples = 5

sample_images = mnist.test.images[:n_samples].reshape([-1, 28, 28, 1])

with tf.Session() as sess:
    saver.restore(sess, checkpoint_path)
    caps2_output_value, decoder_output_value, y_pred_value = sess.run(
            [caps2_output, decoder_output, y_pred],
            feed_dict={X: sample_images,
                       y: np.array([], dtype=np.int64)})


# æ³¨æ„ï¼šæˆ‘ä»¬ä¼ é€’çš„`y`ä½¿ç”¨äº†ä¸€ä¸ªç©ºçš„æ•°ç»„ï¼Œä¸è¿‡TensorFlowå¹¶ä¸ä¼šç”¨åˆ°å®ƒï¼Œå‰é¢å·²ç»è§£é‡Šè¿‡äº†ã€‚

# ç°åœ¨è®©æˆ‘ä»¬æŠŠè¿™äº›å›¾ç‰‡å’Œå®ƒä»¬çš„æ ‡ç­¾ç»˜åˆ¶å‡ºæ¥ï¼ŒåŒæ—¶ç»˜åˆ¶å‡ºæ¥çš„è¿˜æœ‰ç›¸åº”çš„é‡æ–°æ„é€ å’Œé¢„æµ‹ï¼š

# In[150]:


sample_images = sample_images.reshape(-1, 28, 28)
reconstructions = decoder_output_value.reshape([-1, 28, 28])

plt.figure(figsize=(n_samples * 2, 3))
for index in range(n_samples):
    plt.subplot(1, n_samples, index + 1)
    plt.imshow(sample_images[index], cmap="binary")
    plt.title("Label:" + str(mnist.test.labels[index]))
    plt.axis("off")

plt.show()

plt.figure(figsize=(n_samples * 2, 3))
for index in range(n_samples):
    plt.subplot(1, n_samples, index + 1)
    plt.title("Predicted:" + str(y_pred_value[index]))
    plt.imshow(reconstructions[index], cmap="binary")
    plt.axis("off")
    
plt.show()


# é¢„æµ‹éƒ½æ­£ç¡®ï¼Œè€Œä¸”é‡æ–°æ„é€ çš„å›¾ç‰‡çœ‹ä¸Šå»å¾ˆæ£’ã€‚é˜¿å¼¥é™€ä½›ï¼

# # ç†è§£è¾“å‡ºå‘é‡

# è®©æˆ‘ä»¬è°ƒæ•´ä¸€ä¸‹è¾“å‡ºå‘é‡ï¼Œå¯¹å®ƒä»¬çš„å§¿æ€å‚æ•°è¡¨ç¤ºè¿›è¡ŒæŸ¥çœ‹ã€‚

# é¦–å…ˆè®©æˆ‘ä»¬æ£€æŸ¥`cap2_output_value` NumPyæ•°ç»„çš„å½¢çŠ¶ï¼š

# In[151]:


caps2_output_value.shape


# è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°åœ¨æ‰€æœ‰çš„è¾“å‡ºå‘é‡é‡Œå¯¹äºæ¯ä¸ª 16ï¼ˆç»´åº¦ï¼‰å§¿æ€å‚æ•°è¿›è¡Œè°ƒæ•´ã€‚æ¯ä¸ªè°ƒæ•´è¿‡çš„è¾“å‡ºå‘é‡å°†å’ŒåŸæ¥çš„è¾“å‡ºå‘é‡ç›¸åŒï¼Œé™¤äº†å®ƒçš„ å§¿æ€å‚æ•° ä¸­çš„ä¸€ä¸ªä¼šåŠ ä¸Šä¸€ä¸ª-0.5åˆ°0.5ä¹‹é—´å˜åŠ¨çš„å€¼ã€‚é»˜è®¤çš„ä¼šæœ‰11ä¸ªæ­¥æ•°(-0.5, -0.4, ..., +0.4, +0.5)ã€‚è¿™ä¸ªå‡½æ•°ä¼šè¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œå…¶å½¢çŠ¶ä¸º(_è°ƒæ•´è¿‡çš„å§¿æ€å‚æ•°_=16, _æ­¥æ•°_=11, _batch size_=5, 1, 10, 16, 1)ï¼š

# In[152]:


def tweak_pose_parameters(output_vectors, min=-0.5, max=0.5, n_steps=11):
    steps = np.linspace(min, max, n_steps) # -0.25, -0.15, ..., +0.25
    pose_parameters = np.arange(caps2_n_dims) # 0, 1, ..., 15
    tweaks = np.zeros([caps2_n_dims, n_steps, 1, 1, 1, caps2_n_dims, 1])
    tweaks[pose_parameters, :, 0, 0, 0, pose_parameters, 0] = steps
    output_vectors_expanded = output_vectors[np.newaxis, np.newaxis]
    return tweaks + output_vectors_expanded


# è®©æˆ‘ä»¬è®¡ç®—æ‰€æœ‰çš„è°ƒæ•´è¿‡çš„è¾“å‡ºå‘é‡å¹¶ä¸”é‡å¡‘ç»“æœåˆ° (_parameters_Ã—_steps_Ã—_instances_, 1, 10, 16, 1) ä»¥ä¾¿äºæˆ‘ä»¬èƒ½å¤Ÿä¼ é€’è¯¥æ•°ç»„åˆ°è§£ç å™¨ä¸­ï¼š

# In[153]:


n_steps = 11

tweaked_vectors = tweak_pose_parameters(caps2_output_value, n_steps=n_steps)
tweaked_vectors_reshaped = tweaked_vectors.reshape(
    [-1, 1, caps2_n_caps, caps2_n_dims, 1])


# ç°åœ¨è®©æˆ‘ä»¬é€’é€è¿™äº›è°ƒæ•´è¿‡çš„è¾“å‡ºå‘é‡åˆ°è§£ç å™¨å¹¶ä¸”è·å¾—é‡æ–°æ„é€ ï¼Œå®ƒä¼šäº§ç”Ÿï¼š

# In[154]:


tweak_labels = np.tile(mnist.test.labels[:n_samples], caps2_n_dims * n_steps)

with tf.Session() as sess:
    saver.restore(sess, checkpoint_path)
    decoder_output_value = sess.run(
            decoder_output,
            feed_dict={caps2_output: tweaked_vectors_reshaped,
                       mask_with_labels: True,
                       y: tweak_labels})


# è®©æˆ‘ä»¬é‡å¡‘è§£ç å™¨çš„è¾“å‡ºä»¥ä¾¿äºæˆ‘ä»¬èƒ½å¤Ÿåœ¨è¾“å‡ºç»´åº¦ï¼Œè°ƒæ•´æ­¥æ•°ï¼Œå’Œå®ä¾‹ä¹‹ä¸Šè¿›è¡Œè¿­ä»£ï¼š

# In[155]:


tweak_reconstructions = decoder_output_value.reshape(
        [caps2_n_dims, n_steps, n_samples, 28, 28])


# æœ€åï¼Œè®©æˆ‘ä»¬ç»˜åˆ¶æ‰€æœ‰çš„é‡æ–°æ„é€ ï¼Œå¯¹äºå‰ä¸‰ä¸ªè¾“å‡ºç»´åº¦ï¼Œå¯¹äºæ¯ä¸ªè°ƒæ•´ä¸­çš„æ­¥æ•°ï¼ˆåˆ—ï¼‰å’Œæ¯ä¸ªæ•°å­—ï¼ˆè¡Œï¼‰ï¼š

# In[156]:


for dim in range(3):
    print("Tweaking output dimension #{}".format(dim))
    plt.figure(figsize=(n_steps / 1.2, n_samples / 1.5))
    for row in range(n_samples):
        for col in range(n_steps):
            plt.subplot(n_samples, n_steps, row * n_steps + col + 1)
            plt.imshow(tweak_reconstructions[dim, col, row], cmap="binary")
            plt.axis("off")
    plt.show()


# # å°ç»“

# æˆ‘è¯•å›¾è®©è¿™ä¸ªnotebookä¸­çš„ä»£ç å°½é‡çš„æ‰å¹³å’Œçº¿æ€§ï¼Œä¸ºäº†è®©å¤§å®¶å®¹æ˜“è·Ÿä¸Šï¼Œå½“ç„¶åœ¨å®è·µä¸­å¤§å®¶å¯èƒ½æƒ³è¦åŒ…è£…è¿™äº›ä»£ç æˆå¯é‡ç”¨çš„å‡½æ•°å’Œç±»ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥å°è¯•å®ç°ä½ è‡ªå·±çš„`PrimaryCapsuleLayer`ï¼Œå’Œ`DeseRoutingCapsuleLayer` ç±»ï¼Œå…¶å‚æ•°å¯ä»¥æ˜¯èƒ¶å›Šçš„æ•°é‡ï¼Œè·¯ç”±è¿­ä»£çš„æ•°é‡ï¼Œæ˜¯ä½¿ç”¨åŠ¨æ€å¾ªç¯è¿˜æ˜¯é™æ€å¾ªç¯ï¼Œè¯¸å¦‚æ­¤ç±»ã€‚å¯¹äºåŸºäºTensorFlowæ¨¡å—åŒ–çš„èƒ¶å›Šç½‘ç»œçš„å®ç°ï¼Œå¯ä»¥å‚è€ƒ[CapsNet-TensorFlow](https://github.com/naturomics/CapsNet-Tensorflow) é¡¹ç›®ã€‚
# 
# è¿™å°±æ˜¯ä»Šå¤©æ‰€æœ‰çš„å†…å®¹ï¼Œæˆ‘å¸Œæœ›ä½ ä»¬å–œæ¬¢è¿™ä¸ªnotebookï¼
